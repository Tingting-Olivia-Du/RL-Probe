# RL-Probe Configuration
# Token-level KL-Divergence Analysis for RLVR Training Dynamics

# =============================================================================
# Model Configuration
# =============================================================================
models:
  # Base/Reference model (DPO stage, RL starting point)
  base_model: "allenai/Llama-3.1-Tulu-3-8B-DPO"

  # SFT model for additional baseline comparison
  sft_model: "allenai/Llama-3.1-Tulu-3-8B-SFT"

  # RLVR checkpoints to analyze
  # Using revision parameter to load from specific branches
  rlvr_checkpoints:
    - step: 100
      path: "allenai/Llama-3.1-Tulu-3-8B"
      revision: "step_100"  # Branch name on HuggingFace
      stage: "early"
    - step: 200
      path: "allenai/Llama-3.1-Tulu-3-8B"
      revision: "step_200"  # Branch name on HuggingFace
      stage: "early"
    - step: 300
      path: "allenai/Llama-3.1-Tulu-3-8B"
      revision: "step_300"  # Branch name on HuggingFace
      stage: "early"
    - step: 400
      path: "allenai/Llama-3.1-Tulu-3-8B"
      revision: "step_400"  # Branch name on HuggingFace
      stage: "mid"
    - step: 500
      path: "allenai/Llama-3.1-Tulu-3-8B"
      revision: "step_500"  # Branch name on HuggingFace
      stage: "mid"
    - step: 600
      path: "allenai/Llama-3.1-Tulu-3-8B"
      revision: "step_600"  # Branch name on HuggingFace
      stage: "mid"
    - step: 700
      path: "allenai/Llama-3.1-Tulu-3-8B"
      revision: "step_700"  # Branch name on HuggingFace
      stage: "mid"
    - step: 800
      path: "allenai/Llama-3.1-Tulu-3-8B"
      revision: "step_800"  # Branch name on HuggingFace
      stage: "late"
    - step: 900
      path: "allenai/Llama-3.1-Tulu-3-8B"
      revision: "step_900"  # Branch name on HuggingFace
      stage: "late"
    - step: 1000
      path: "allenai/Llama-3.1-Tulu-3-8B"
      revision: "step_1000"  # Branch name on HuggingFace
      stage: "final"

# =============================================================================
# Dataset Configuration
# =============================================================================
dataset:
  name: "EleutherAI/hendrycks_math"
  subjects: ["all"]  # Use "all" to load all subjects, or specify: ["algebra", "geometry", etc.]
  levels: [3, 4]  # Mid-difficulty problems
  split: "test"

  # Filtering criteria
  filter:
    dpo_correct: false   # DPO model gets it wrong
    rlvr_correct: true   # Final RLVR model gets it right

  # Sampling configuration
  max_problems: 500      # Maximum problems to analyze
  seed: 42

# =============================================================================
# Rollout Configuration
# =============================================================================
rollout:
  # Number of rollouts per problem for diversity analysis
  num_samples_per_problem: 5

  # Generation parameters for DPO rollouts
  generation:
    max_new_tokens: 2048
    temperature: 0.7
    top_p: 0.95
    do_sample: true

  # Storage
  save_dir: "rollouts/dpo_errors"

# =============================================================================
# Analysis Configuration
# =============================================================================
analysis:
  # KL divergence settings
  kl_divergence:
    # Compute both directions for comprehensive analysis
    compute_forward: true   # D_KL(RLVR || DPO)
    compute_reverse: true   # D_KL(DPO || RLVR)
    compute_js: true        # Jensen-Shannon divergence (symmetric)

    # Numerical stability
    epsilon: 1e-10

  # Spike detection
  spike_detection:
    method: "zscore"        # Options: zscore, percentile, adaptive
    threshold: 2.0          # z-score threshold for spike detection
    min_spike_distance: 3   # Minimum tokens between spikes

  # Entropy analysis
  entropy:
    compute: true
    normalize: true         # Normalize by vocab size

  # Token classification
  token_classification:
    enabled: true
    categories:
      - "math_symbol"       # +, -, *, /, =, etc.
      - "number"            # Digits and numeric expressions
      - "logical"           # therefore, because, if, then
      - "step_marker"       # Step 1, First, Next, etc.
      - "variable"          # x, y, n, etc.
      - "other"

# =============================================================================
# Baseline Comparisons
# =============================================================================
baselines:
  # Compare DPO vs SFT to isolate RLVR contribution
  dpo_vs_sft:
    enabled: true

  # Compare across RLVR checkpoints
  checkpoint_progression:
    enabled: true
    pairs:
      - ["step_400", "dpo"]
      - ["step_1200", "step_400"]
      - ["step_2440", "step_1200"]

# =============================================================================
# Visualization Configuration
# =============================================================================
visualization:
  # Output directory
  output_dir: "outputs/figures"

  # Figure formats
  formats: ["png", "pdf"]
  dpi: 300

  # Heatmap settings
  heatmap:
    cmap: "RdYlBu_r"
    figsize: [16, 8]

  # Line plot settings
  lineplot:
    figsize: [14, 6]
    show_spikes: true
    spike_color: "red"

  # Case study settings
  case_study:
    num_cases: 3
    detailed_analysis: true

# =============================================================================
# Quantitative Metrics
# =============================================================================
metrics:
  # Aggregate statistics
  aggregate:
    - "mean_kl_by_checkpoint"
    - "spike_density_by_region"    # early/mid/late reasoning
    - "entropy_reduction_rate"

  # Correlation analysis
  correlation:
    with_correctness: true
    with_problem_difficulty: true

  # Statistical tests
  significance:
    test: "wilcoxon"
    alpha: 0.05

# =============================================================================
# Hardware & Runtime
# =============================================================================
hardware:
  # Device configuration options:
  #   - "cuda" or "cuda:0": 单 GPU（默认使用第一张）
  #   - "cuda:1", "cuda:2": 指定具体 GPU
  #   - "auto": 自动将模型分片到所有可用 GPU（推荐多 GPU）
  #   - "balanced": 均匀分配到所有 GPU
  #   - "sequential": 按顺序填充 GPU
  device: "balanced"
  dtype: "bfloat16"
  batch_size: 4
  num_workers: 4

  # 多 GPU 配置（当 device 为 "auto"/"balanced"/"sequential" 时生效）
  multi_gpu:
    enabled: true           # 是否启用多 GPU
    gpu_ids: [0, 4, 5]            # 指定 GPU ID 列表，如 [0, 1, 2]，null 表示使用所有可用 GPU
    max_memory_per_gpu: 40GB # 每个 GPU 最大显存，如 "20GiB"，null 表示不限制

# Logging
logging:
  level: "INFO"
  save_logs: true
  log_dir: "outputs/logs"

# Reproducibility
seed: 42
