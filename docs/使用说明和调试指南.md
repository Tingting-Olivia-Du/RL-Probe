# RL-Probe 使用说明和调试指南

## 目录
1. [快速开始](#快速开始)
2. [脚本调用说明](#脚本调用说明)
3. [常见问题调试](#常见问题调试)
4. [问题匹配检查](#问题匹配检查)
5. [GPU 配置说明](#gpu-配置说明)
6. [KL 散度计算说明](#kl-散度计算说明)

---

## 快速开始

### 环境准备

```bash
# 安装依赖
pip install -r requirements.txt

# 确保安装了 sympy 和 antlr4（用于数学等价性检查）
pip install sympy antlr4-python3-runtime
```

### 完整流程

```bash
# 步骤1: 准备数据（评测模型，筛选问题）
python scripts/01_prepare_data.py --model both --gpu 6 --max-questions 50

# 步骤2: 生成 rollouts（从 DPO 模型生成推理轨迹）
python scripts/02_generate_rollouts.py --gpu 6 --max-problems 10

# 步骤3: 计算 KL 散度（分析模型差异）
python scripts/03_compute_kl.py --gpu 6 --checkpoint rlvr_step_1000

# 步骤4: 可视化结果
python scripts/04_visualize.py
```

---

## 脚本调用说明

### 1. 数据准备脚本 (`01_prepare_data.py`)

**功能**: 加载 MATH-500 数据集，评测 DPO 和 RLVR 模型，筛选出 DPO 错误但 RLVR 正确的问题。

**基本用法**:
```bash
python scripts/01_prepare_data.py --model dpo --gpu 6 --max-questions 50
```

**参数说明**:
- `--model`: 选择评测的模型
  - `dpo`: 只评测 DPO 模型
  - `rlvr`: 只评测 RLVR 模型
  - `both`: 评测两个模型（默认）
- `--gpu`: 指定使用的 GPU
  - `6`: 使用 GPU 6（单 GPU）
  - `0,1,2`: 使用多个 GPU（多 GPU 模式）
  - `cuda:1`: 直接指定设备
- `--max-questions`: 每次运行评测的新问题数量
  - `50`: 评测 50 个新问题（默认）
  - `0` 或 `-1`: 评测所有问题
- `--skip-dpo`: 跳过 DPO 评测，使用缓存结果
- `--skip-rlvr`: 跳过 RLVR 评测，使用缓存结果
- `--skip-eval`: 跳过所有评测，只进行过滤
- `--rlvr-checkpoint`: 指定 RLVR checkpoint（默认使用 final）
- `--config`: 配置文件路径（默认 `configs/config.yaml`）
- `--output-dir`: 输出目录（默认 `data/filtered`）

**输出文件**:
- `dpo_results.json`: DPO 模型评测结果（简洁版：problem_id -> correct）
- `rlvr_results.json`: RLVR 模型评测结果（简洁版）
- `dpo_responses.json`: DPO 模型完整回答（包含 response, correct, ground_truth）
- `rlvr_responses.json`: RLVR 模型完整回答
- `filtered_problems.json`: 筛选后的问题（DPO 错误且 RLVR 正确）

**自动保存**: 每评测 10 个新问题会自动保存一次，避免数据丢失。

**示例**:
```bash
# 先评测 DPO 模型 50 题
python scripts/01_prepare_data.py --model dpo --gpu 6 --max-questions 50

# 继续评测 DPO 模型（自动从上次停止的地方继续）
python scripts/01_prepare_data.py --model dpo --gpu 6 --max-questions 50

# 评测 RLVR 模型
python scripts/01_prepare_data.py --model rlvr --gpu 2 --max-questions 50

# 两个模型都评测完后，进行过滤
python scripts/01_prepare_data.py --skip-eval
```

---

### 2. Rollout 生成脚本 (`02_generate_rollouts.py`)

**功能**: 从 DPO 模型生成多样化的推理轨迹（rollouts），用于后续的 KL 散度分析。

**基本用法**:
```bash
python scripts/02_generate_rollouts.py --gpu 6 --max-problems 10
```

**参数说明**:
- `--gpu`: 指定使用的 GPU（**已添加支持**）
  - `6`: 使用 GPU 6
  - `0,1,2`: 使用多个 GPU
- `--problems`: 输入问题文件路径（默认 `data/filtered/filtered_problems.json`）
- `--output-dir`: 输出目录（默认 `rollouts/dpo_errors`）
- `--num-samples`: 每个问题生成的 rollouts 数量（覆盖配置文件）
- `--max-problems`: 限制处理的问题数量（用于测试）
- `--config`: 配置文件路径

**输出文件**:
- `all_rollouts.json`: 所有生成的 rollouts
- `rollouts_checkpoint.json`: 每 10 个问题保存一次的检查点

**示例**:
```bash
# 为前 10 个问题生成 rollouts
python scripts/02_generate_rollouts.py --gpu 6 --max-problems 10

# 生成更多 rollouts（每个问题 10 个样本）
python scripts/02_generate_rollouts.py --gpu 6 --num-samples 10
```

---

### 3. KL 散度计算脚本 (`03_compute_kl.py`)

**功能**: 计算 RLVR 模型和 DPO 模型之间的 token-level KL 散度，分析模型差异。

**基本用法**:
```bash
python scripts/03_compute_kl.py --gpu 6 --checkpoint rlvr_step_1000
```

**参数说明**:
- `--gpu`: 指定使用的 GPU（**已添加支持**）
- `--rollouts`: Rollouts 文件路径（默认 `rollouts/dpo_errors/all_rollouts.json`）
- `--output-dir`: 输出目录（默认 `outputs/results`）
- `--checkpoint`: 指定要分析的 checkpoint（默认分析所有）
- `--config`: 配置文件路径

**输出文件**:
- `{checkpoint}_results.json`: 每个 checkpoint 的分析结果
- `all_results.pkl`: 所有结果的合并文件

**示例**:
```bash
# 分析特定 checkpoint
python scripts/03_compute_kl.py --gpu 6 --checkpoint rlvr_step_1000

# 分析所有 checkpoints
python scripts/03_compute_kl.py --gpu 6
```

---

## 常见问题调试

### 1. 数据集加载问题

**问题**: `Total problems: 0` 或 `ValueError: BuilderConfig 'algebra' not found`

**原因**: MATH-500 数据集只有 `'default'` 配置，不支持按 subject 分配置加载。

**解决方案**: 代码已修复，会自动：
- 加载整个数据集
- 通过 `subject` 字段过滤
- 通过 `level` 字段过滤

**调试方法**:
```bash
# 查看数据集加载日志
python scripts/01_prepare_data.py --model dpo --gpu 6 --max-questions 1

# 检查日志输出：
# - "Loaded raw dataset: X problems"
# - "Dataset features: [...]"
# - "First example level: ..."
# - "After subject filtering: X problems"
# - "After level filtering: X -> Y problems"
```

---

### 2. 问题 ID 不匹配问题

**问题**: DPO 和 RLVR 结果的 problem_id 不一致

**检查方法**:
```bash
# 运行匹配检查脚本
python scripts/match_problem.py
```

**输出说明**:
- `两个都有的 ID 数`: 匹配的 problem_id 数量
- `只在 DPO 中的 ID 数`: DPO 独有的 problem_id
- `只在 RLVR 中的 ID 数`: RLVR 独有的 problem_id
- `DPO✗ RLVR✓`: DPO 错误但 RLVR 正确的问题（这是我们需要的）

**问题原因**:
1. **ID 生成不一致**: 不同脚本使用不同的 ID 生成逻辑
2. **Hash 值可能为负数**: Python 的 `hash()` 可能返回负数，转换为字符串时可能不一致

**解决方案**: ✅ **已修复**
- 统一使用 `unique_id` 字段（如果数据集有）
- 如果没有 `unique_id`，使用 `hash_{abs(hash(problem))}` 格式
- 所有脚本（`01_prepare_data.py`, `02_generate_rollouts.py`, `src/data/dataset.py`）都使用相同的 ID 生成逻辑

**修复后的逻辑**:
```python
# 优先使用 unique_id，否则使用稳定的 hash（确保为正数）
problem_id = problem.get("unique_id") or f"hash_{abs(hash(problem.get('problem', '')))}"
```

---

### 3. GPU 配置问题

**问题**: 脚本没有使用指定的 GPU

**检查方法**:
```bash
# 查看日志中的 GPU 使用信息
python scripts/01_prepare_data.py --model dpo --gpu 6 --max-questions 1

# 应该看到：
# "Using single GPU: cuda:6"
```

**已修复的脚本**:
- ✅ `01_prepare_data.py`: 支持 `--gpu` 参数
- ✅ `02_generate_rollouts.py`: **已添加** `--gpu` 参数支持
- ✅ `03_compute_kl.py`: **已添加** `--gpu` 参数支持

**使用方法**:
```bash
# 单 GPU
python scripts/02_generate_rollouts.py --gpu 6

# 多 GPU
python scripts/02_generate_rollouts.py --gpu 0,1,2

# 直接指定设备
python scripts/02_generate_rollouts.py --gpu cuda:1
```

---

### 4. 内存不足问题

**问题**: `CUDA out of memory`

**解决方案**:
1. **减少批次大小**: 在配置文件中设置 `batch_size: 1`
2. **使用多 GPU**: `--gpu 0,1,2` 自动分配显存
3. **限制问题数量**: `--max-questions 10` 或 `--max-problems 10`
4. **使用 CPU**: `--gpu cpu`（很慢，不推荐）

---

### 5. 数学等价性检查问题

**问题**: SymPy 等价性检查失败

**检查方法**:
```bash
# 查看日志
# 应该看到：
# "SymPy-based equivalence checking enabled"
# 或
# "Using string-based comparison (SymPy disabled or unavailable)"
```

**解决方案**:
```bash
# 安装依赖
pip install sympy antlr4-python3-runtime

# 如果 LaTeX 解析失败，会自动回退到字符串比较
```

---

## 问题匹配检查

### 使用 `match_problem.py` 脚本

**功能**: 检查 DPO 和 RLVR 结果的 problem_id 匹配情况，统计各种结果组合。

**运行**:
```bash
python scripts/match_problem.py
```

**输出示例**:
```
DPO 结果总数: 50
RLVR 结果总数: 50

=== Match 统计 ===
两个都有的 ID 数: 45
只在 DPO 中的 ID 数: 5
只在 RLVR 中的 ID 数: 5

=== Match ID 的结果组合 ===
DPO✓ RLVR✓ (都对): 20
DPO✗ RLVR✗ (都错): 10
DPO✓ RLVR✗ (DPO对RLVR错): 5
DPO✗ RLVR✓ (DPO错RLVR对): 10  ← 这是我们需要的
```

**输出文件**: `data/filtered/match_problem_analysis.json`

**问题诊断**:
- 如果 `两个都有的 ID 数` 很少，说明 ID 生成不一致
- 如果 `DPO✗ RLVR✓` 为 0，说明没有符合筛选条件的问题

---

## GPU 配置说明

### 配置文件方式

在 `configs/config.yaml` 中配置：
```yaml
hardware:
  device: "cuda:6"  # 或 "auto", "balanced", "sequential"
  dtype: "bfloat16"
  multi_gpu:
    enabled: true
    gpu_ids: [0, 1, 2]
    max_memory_per_gpu: 40GB
```

### 命令行方式（推荐）

**所有脚本都支持 `--gpu` 参数**:
```bash
# 单 GPU
--gpu 6

# 多 GPU
--gpu 0,1,2

# 直接指定设备
--gpu cuda:1
```

**优先级**: 命令行参数 > 配置文件

---

## KL 散度计算说明

### 计算原理

KL 散度用于衡量两个概率分布之间的差异：

1. **Forward KL**: `D_KL(P || Q)` = RLVR || DPO
   - 衡量 RLVR 分布相对于 DPO 分布的差异
   - 值越大，说明 RLVR 在该 token 上的分布与 DPO 差异越大

2. **Reverse KL**: `D_KL(Q || P)` = DPO || RLVR
   - 衡量 DPO 分布相对于 RLVR 分布的差异

3. **Jensen-Shannon Divergence**: 对称的散度度量
   - `JS(P||Q) = 0.5 * D_KL(P||M) + 0.5 * D_KL(Q||M)`
   - 其中 `M = 0.5 * (P + Q)`

### 计算流程

1. **Teacher Forcing**: 使用 DPO 生成的 rollout 作为输入
2. **获取 Logits**: 从两个模型获取每个 token 位置的 logits
3. **转换为概率**: 使用 softmax 转换为概率分布
4. **计算 KL**: 对每个 token 位置计算 KL 散度
5. **数值稳定性**: 添加 epsilon (1e-10) 避免数值问题

### 代码位置

- **核心计算**: `src/analysis/kl_divergence.py`
  - `compute_kl_divergence()`: KL 散度计算
  - `compute_js_divergence()`: JS 散度计算
  - `analyze_rollout()`: 分析完整的 rollout

- **调用脚本**: `scripts/03_compute_kl.py`

### 检查 KL 计算是否正确

**验证方法**:
1. **检查数值范围**: KL 散度应该 >= 0
2. **检查对称性**: Forward 和 Reverse KL 通常不同（除非分布相同）
3. **检查异常值**: 如果某个 token 的 KL 值特别大，可能是模型在该位置有显著差异

**调试输出**:
```bash
# 查看 KL 分析摘要
python scripts/03_compute_kl.py --gpu 6

# 输出示例：
# KL Analysis Summary
# rlvr_step_1000:
#   Analyses: 50
#   Mean KL: 0.1234 +/- 0.0567
#   Total spikes: 234
```

### 常见问题

1. **KL 值为 NaN**: 
   - 检查 epsilon 是否足够大
   - 检查概率分布是否归一化

2. **KL 值过大**:
   - 可能是模型在该位置有根本性差异
   - 检查 tokenizer 是否一致

3. **计算速度慢**:
   - 减少 `max-problems` 数量
   - 使用更少的 rollouts
   - 使用多 GPU 加速

---

## 总结

### 完整工作流程

```bash
# 1. 准备数据（评测模型）
python scripts/01_prepare_data.py --model both --gpu 6 --max-questions 50

# 2. 检查问题匹配
python scripts/match_problem.py

# 3. 生成 rollouts
python scripts/02_generate_rollouts.py --gpu 6 --max-problems 10

# 4. 计算 KL 散度
python scripts/03_compute_kl.py --gpu 6 --checkpoint rlvr_step_1000

# 5. 可视化
python scripts/04_visualize.py
```

### 关键检查点

1. ✅ **问题 ID 匹配**: 运行 `match_problem.py` 检查
2. ✅ **GPU 配置**: 所有脚本都支持 `--gpu` 参数
3. ✅ **KL 计算**: 检查数值范围和异常值
4. ✅ **自动保存**: 每 10 个问题自动保存，避免数据丢失

### 获取帮助

如果遇到问题，请检查：
1. 日志输出中的错误信息
2. 输出文件的内容和格式
3. GPU 使用情况（`nvidia-smi`）
4. 数据集加载情况（查看调试日志）
