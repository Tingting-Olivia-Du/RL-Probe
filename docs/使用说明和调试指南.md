# RL-Probe 使用说明和调试指南

## 目录
1. [快速开始](#快速开始)
2. [脚本调用说明](#脚本调用说明)
3. [常见问题调试](#常见问题调试)
4. [问题匹配检查](#问题匹配检查)
5. [GPU 配置说明](#gpu-配置说明)
6. [KL 散度计算说明](#kl-散度计算说明)

---

## 快速开始

### 环境准备

```bash
# 安装依赖
pip install -r requirements.txt

# 确保安装了 sympy 和 antlr4（用于数学等价性检查）
pip install sympy antlr4-python3-runtime

# 配置 HuggingFace Token（用于访问私有模型）
# 1. 复制 .env.example 到 .env
cp .env.example .env

# 2. 编辑 .env 文件，添加你的 HuggingFace token
# 或者直接设置环境变量：
export HF_TOKEN=your_token_here
```

**注意**: `.env` 文件已添加到 `.gitignore`，不会被提交到 Git。

### 完整流程

```bash
# 步骤1: 准备数据（评测模型，筛选问题）
python scripts/01_prepare_data.py --model both --gpu 6 --max-questions 50

# 步骤2: 计算 KL 散度（分析模型差异，使用 DPO responses 作为 rollouts）
# 方法1: 使用 DPO responses 作为 rollouts（推荐）
python scripts/03_compute_kl.py --use-dpo-responses --gpu 6 --checkpoint rlvr_step_1000

# 方法2: 使用生成的 rollouts
python scripts/03_compute_kl.py --gpu 6 --rollouts rollouts/rlvr_step_500/all_rollouts.json

# 步骤4: 可视化结果
python scripts/04_visualize.py
```

---

## 脚本调用说明

### 1. 数据准备脚本 (`01_prepare_data.py`)

**功能**: 加载 MATH-500 数据集，评测 DPO 和 RLVR 模型，筛选出 DPO 错误但 RLVR 正确的问题。

**基本用法**:
```bash
python scripts/01_prepare_data.py --model dpo --gpu 6 --max-questions 50
```

**参数说明**:
- `--model`: 选择评测的模型
  - `dpo`: 只评测 DPO 模型
  - `rlvr`: 只评测 RLVR 模型
  - `both`: 评测两个模型（默认）
- `--gpu`: 指定使用的 GPU
  - `6`: 使用 GPU 6（单 GPU）
  - `0,1,2`: 使用多个 GPU（多 GPU 模式）
  - `cuda:1`: 直接指定设备
- `--max-questions`: 每次运行评测的新问题数量
  - `50`: 评测 50 个新问题（默认）
  - `0` 或 `-1`: 评测所有问题
- `--skip-dpo`: 跳过 DPO 评测，使用缓存结果
- `--skip-rlvr`: 跳过 RLVR 评测，使用缓存结果
- `--skip-eval`: 跳过所有评测，只进行过滤
- `--rlvr-checkpoint`: 指定 RLVR checkpoint（默认使用 final）
- `--config`: 配置文件路径（默认 `configs/config.yaml`）
- `--output-dir`: 输出目录（默认 `data/filtered`）

**输出文件**:
- `dpo_results.json`: DPO 模型评测结果（简洁版：problem_id -> correct）
- `rlvr_results.json`: RLVR 模型评测结果（简洁版）
- `dpo_responses.json`: DPO 模型完整回答（包含 response, correct, ground_truth）
- `rlvr_responses.json`: RLVR 模型完整回答
- `filtered_problems.json`: 筛选后的问题（DPO 错误且 RLVR 正确）

**自动保存**: 每评测 10 个新问题会自动保存一次，避免数据丢失。

**示例**:
```bash
# 先评测 DPO 模型 50 题
python scripts/01_prepare_data.py --model dpo --gpu 6 --max-questions 50

# 继续评测 DPO 模型（自动从上次停止的地方继续）
python scripts/01_prepare_data.py --model dpo --gpu 6 --max-questions 50

# 评测 RLVR 模型
python scripts/01_prepare_data.py --model rlvr --gpu 2 --max-questions 50

# 两个模型都评测完后，进行过滤
python scripts/01_prepare_data.py --skip-eval
```

---

### 2. KL 散度计算脚本 (`03_compute_kl.py`)

**功能**: 计算 RLVR 模型和 DPO 模型之间的 token-level KL 散度，分析模型差异。

**基本用法**:
```bash
# 使用 DPO responses 作为 rollouts（推荐）
# 分析单个 checkpoint
python scripts/03_compute_kl.py --use-dpo-responses --gpu 0 --checkpoint rlvr_step_500

# 分析所有 checkpoints（不指定 --checkpoint）
python scripts/03_compute_kl.py --use-dpo-responses --gpu 0
```

**参数说明**:
- `--gpu`: 指定使用的 GPU（**已添加支持**）
- `--use-dpo-responses`: **使用 DPO responses 作为 rollouts**（必需）
  - 直接从 `dpo_responses.json` 读取 DPO 生成的错误推理
  - 只处理 `filtered_problems.json` 中的问题（DPO错误但RLVR正确）
- `--dpo-responses`: DPO responses 文件路径（默认 `data/filtered/dpo_responses.json`）
- `--output-dir`: 输出目录（默认 `outputs/results`）
- `--checkpoint`: 指定要分析的 checkpoint（默认分析所有）
- `--config`: 配置文件路径

**输出文件**:
- `{checkpoint}_results.json`: 每个 checkpoint 的分析结果
- `all_results.pkl`: 所有结果的合并文件

**示例**:
```bash
# 使用 DPO responses（推荐，最快）
python scripts/03_compute_kl.py --use-dpo-responses --gpu 6 --checkpoint rlvr_step_1000

# 分析所有 checkpoints，使用 DPO responses
python scripts/03_compute_kl.py --use-dpo-responses --gpu 6

# 使用生成的 rollouts
python scripts/03_compute_kl.py --gpu 6 --rollouts rollouts/rlvr_step_500/all_rollouts.json
```

**为什么推荐使用 `--use-dpo-responses`**:
- ✅ 使用 DPO 实际生成的错误推理（真实错误）
- ✅ 无需重新生成 rollouts，节省时间和计算资源
- ✅ 这些 responses 已经保存在 `dpo_responses.json` 中
- ✅ 符合分析逻辑：使用 DPO 的错误作为起点，分析 RLVR 如何反应

---

## 常见问题调试

### 1. 数据集加载问题

**问题**: `Total problems: 0` 或 `ValueError: BuilderConfig 'algebra' not found`

**原因**: MATH-500 数据集只有 `'default'` 配置，不支持按 subject 分配置加载。

**解决方案**: 代码已修复，会自动：
- 加载整个数据集
- 通过 `subject` 字段过滤
- 通过 `level` 字段过滤

**调试方法**:
```bash
# 查看数据集加载日志
python scripts/01_prepare_data.py --model dpo --gpu 6 --max-questions 1

# 检查日志输出：
# - "Loaded raw dataset: X problems"
# - "Dataset features: [...]"
# - "First example level: ..."
# - "After subject filtering: X problems"
# - "After level filtering: X -> Y problems"
```

---

### 2. 问题 ID 不匹配问题

**问题**: DPO 和 RLVR 结果的 problem_id 不一致

**检查方法**:
```bash
# 运行匹配检查脚本
python scripts/match_problem.py
```

**输出说明**:
- `两个都有的 ID 数`: 匹配的 problem_id 数量
- `只在 DPO 中的 ID 数`: DPO 独有的 problem_id
- `只在 RLVR 中的 ID 数`: RLVR 独有的 problem_id
- `DPO✗ RLVR✓`: DPO 错误但 RLVR 正确的问题（这是我们需要的）

**问题原因**:
1. **ID 生成不一致**: 不同脚本使用不同的 ID 生成逻辑
2. **Hash 值可能为负数**: Python 的 `hash()` 可能返回负数，转换为字符串时可能不一致

**解决方案**: ✅ **已修复**
- 统一使用 `unique_id` 字段（如果数据集有）
- 如果没有 `unique_id`，使用 `hash_{abs(hash(problem))}` 格式
- 所有脚本（`01_prepare_data.py`, `03_compute_kl.py`, `src/data/dataset.py`）都使用相同的 ID 生成逻辑

**修复后的逻辑**:
```python
# 优先使用 unique_id，否则使用稳定的 hash（确保为正数）
problem_id = problem.get("unique_id") or f"hash_{abs(hash(problem.get('problem', '')))}"
```

---

### 3. GPU 配置问题

**问题**: 脚本没有使用指定的 GPU

**检查方法**:
```bash
# 查看日志中的 GPU 使用信息
python scripts/01_prepare_data.py --model dpo --gpu 6 --max-questions 1

# 应该看到：
# "Using single GPU: cuda:6"
```

**已修复的脚本**:
- ✅ `01_prepare_data.py`: 支持 `--gpu` 参数
- ✅ `03_compute_kl.py`: **已添加** `--gpu` 参数支持

**使用方法**:
```bash
# 单 GPU
python scripts/03_compute_kl.py --use-dpo-responses --gpu 6

# 多 GPU
python scripts/03_compute_kl.py --use-dpo-responses --gpu 0,1,2

# 直接指定设备
python scripts/03_compute_kl.py --use-dpo-responses --gpu cuda:1
```

---

### 4. TypeError: unsupported operand type(s) for +: 'Tensor' and 'str'

**问题**: `TypeError: unsupported operand type(s) for +: 'Tensor' and 'str'` 在 `kl_divergence.py` 第 118 行

**原因**: YAML 配置文件中的 `epsilon: 1e-10` 被解析为字符串而不是浮点数

**解决方案**: ✅ **已修复**
- 在 `03_compute_kl.py` 中添加了类型转换，确保 epsilon 是浮点数
- 如果配置文件中是字符串，会自动转换为浮点数

**修复后的代码**:
```python
# Ensure epsilon is a float (YAML might parse 1e-10 as string)
epsilon = config["analysis"]["kl_divergence"]["epsilon"]
if isinstance(epsilon, str):
    epsilon = float(epsilon)
```

---

### 5. 内存不足问题

**问题**: `CUDA out of memory`

**原因分析**:
- `--checkpoint rlvr_step_500` 会同时加载两个大模型：
  - **RLVR checkpoint 500** (约 15-16 GiB)
  - **DPO 模型** (约 15-16 GiB)
- 如果 GPU 上已有其他进程占用内存，会导致 OOM

**解决方案**:

1. **检查 GPU 使用情况**:
```bash
# 查看 GPU 6 上的进程
nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv -i 6

# 或者查看所有 GPU
nvidia-smi
```

2. **清理其他进程**（如果不需要）:
```bash
# 杀死占用 GPU 6 的进程（谨慎使用！）
kill -9 <PID>
```

3. **使用空闲的 GPU**:
```bash
# 查看所有 GPU 的使用情况
nvidia-smi

# 使用空闲的 GPU（例如 GPU 0）
python scripts/03_compute_kl.py --use-dpo-responses --gpu 0 --checkpoint rlvr_step_500
```

4. **使用多 GPU 自动分配**:
```bash
# 让系统自动分配显存到多个 GPU
python scripts/03_compute_kl.py --use-dpo-responses --gpu 0,1,2 --checkpoint rlvr_step_500
```

5. **限制处理的问题数量**（用于测试）:
```bash
# 先处理少量问题测试
# 注意：需要修改代码添加 --max-problems 参数，或手动限制 filtered_problems.json
```

6. **使用 CPU offload**（如果 GPU 内存不足）:
   - 修改配置文件，添加 `device_map: "auto"` 和 `max_memory` 设置
   - 让部分模型层 offload 到 CPU（会很慢）

---

### 5. 数学等价性检查问题

**问题**: SymPy 等价性检查失败

**检查方法**:
```bash
# 查看日志
# 应该看到：
# "SymPy-based equivalence checking enabled"
# 或
# "Using string-based comparison (SymPy disabled or unavailable)"
```

**解决方案**:
```bash
# 安装依赖
pip install sympy antlr4-python3-runtime

# 如果 LaTeX 解析失败，会自动回退到字符串比较
```

---

## 问题匹配检查

### 使用 `match_problem.py` 脚本

**功能**: 检查 DPO 和 RLVR 结果的 problem_id 匹配情况，统计各种结果组合。

**运行**:
```bash
python scripts/match_problem.py
```

**输出示例**:
```
DPO 结果总数: 50
RLVR 结果总数: 50

=== Match 统计 ===
两个都有的 ID 数: 45
只在 DPO 中的 ID 数: 5
只在 RLVR 中的 ID 数: 5

=== Match ID 的结果组合 ===
DPO✓ RLVR✓ (都对): 20
DPO✗ RLVR✗ (都错): 10
DPO✓ RLVR✗ (DPO对RLVR错): 5
DPO✗ RLVR✓ (DPO错RLVR对): 10  ← 这是我们需要的
```

**输出文件**: `data/filtered/match_problem_analysis.json`

**问题诊断**:
- 如果 `两个都有的 ID 数` 很少，说明 ID 生成不一致
- 如果 `DPO✗ RLVR✓` 为 0，说明没有符合筛选条件的问题

---

## GPU 配置说明

### 配置文件方式

在 `configs/config.yaml` 中配置：
```yaml
hardware:
  device: "cuda:6"  # 或 "auto", "balanced", "sequential"
  dtype: "bfloat16"
  multi_gpu:
    enabled: true
    gpu_ids: [0, 1, 2]
    max_memory_per_gpu: 40GB
```

### 命令行方式（推荐）

**所有脚本都支持 `--gpu` 参数**:
```bash
# 单 GPU
--gpu 6

# 多 GPU
--gpu 0,1,2

# 直接指定设备
--gpu cuda:1
```

**优先级**: 命令行参数 > 配置文件

---

## KL 散度计算说明

### 计算原理

KL 散度用于衡量两个概率分布之间的差异：

1. **Forward KL**: `D_KL(P || Q)` = RLVR || DPO
   - 衡量 RLVR 分布相对于 DPO 分布的差异
   - 值越大，说明 RLVR 在该 token 上的分布与 DPO 差异越大

2. **Reverse KL**: `D_KL(Q || P)` = DPO || RLVR
   - 衡量 DPO 分布相对于 RLVR 分布的差异

3. **Jensen-Shannon Divergence**: 对称的散度度量
   - `JS(P||Q) = 0.5 * D_KL(P||M) + 0.5 * D_KL(Q||M)`
   - 其中 `M = 0.5 * (P + Q)`

### 计算流程

1. **Teacher Forcing**: 使用 DPO 生成的 rollout 作为输入
2. **获取 Logits**: 从两个模型获取每个 token 位置的 logits
3. **转换为概率**: 使用 softmax 转换为概率分布
4. **计算 KL**: 对每个 token 位置计算 KL 散度
5. **数值稳定性**: 添加 epsilon (1e-10) 避免数值问题

### 代码位置

- **核心计算**: `src/analysis/kl_divergence.py`
  - `compute_kl_divergence()`: KL 散度计算
  - `compute_js_divergence()`: JS 散度计算
  - `analyze_rollout()`: 分析完整的 rollout

- **调用脚本**: `scripts/03_compute_kl.py`

### 检查 KL 计算是否正确

**验证方法**:
1. **检查数值范围**: KL 散度应该 >= 0
2. **检查对称性**: Forward 和 Reverse KL 通常不同（除非分布相同）
3. **检查异常值**: 如果某个 token 的 KL 值特别大，可能是模型在该位置有显著差异

**调试输出**:
```bash
# 查看 KL 分析摘要
python scripts/03_compute_kl.py --gpu 6

# 输出示例：
# KL Analysis Summary
# rlvr_step_1000:
#   Analyses: 50
#   Mean KL: 0.1234 +/- 0.0567
#   Total spikes: 234
```

### 常见问题

1. **KL 值为 NaN**: 
   - 检查 epsilon 是否足够大
   - 检查概率分布是否归一化

2. **KL 值过大**:
   - 可能是模型在该位置有根本性差异
   - 检查 tokenizer 是否一致

3. **计算速度慢**:
   - 减少 `max-problems` 数量
   - 使用更少的 rollouts
   - 使用多 GPU 加速

---

## 总结

### 完整工作流程

```bash
# 1. 准备数据（评测模型）
python scripts/01_prepare_data.py --model both --gpu 6 --max-questions 50

# 2. 检查问题匹配
python scripts/match_problem.py

# 3. 计算 KL 散度（使用 DPO responses 作为 rollouts）
python scripts/03_compute_kl.py --use-dpo-responses --gpu 6 --checkpoint rlvr_step_1000

# 5. 可视化
python scripts/04_visualize.py
```

### 关键检查点

1. ✅ **问题 ID 匹配**: 运行 `match_problem.py` 检查
2. ✅ **GPU 配置**: 所有脚本都支持 `--gpu` 参数
3. ✅ **KL 计算**: 检查数值范围和异常值
4. ✅ **自动保存**: 每 10 个问题自动保存，避免数据丢失

### 获取帮助

如果遇到问题，请检查：
1. 日志输出中的错误信息
2. 输出文件的内容和格式
3. GPU 使用情况（`nvidia-smi`）
4. 数据集加载情况（查看调试日志）
